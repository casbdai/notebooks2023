{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtXEcvNWPZpr",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Hands On - Ridge Regressions for more accurate Bordeaux Equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by2o89GI97z5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Import Data & Check Structure\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQWjq9jR-O7L",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "wine = pd.read_csv(\"https://raw.githubusercontent.com/casbdai/datasets/main/wine_regression.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAV-m4f5-tX0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Separate Features and Targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "replRE6zVsd5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "X = wine.drop(\"price\", axis = 1)\n",
        "X = X.drop(\"vintage\", axis = 1)\n",
        "y = wine[\"price\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3gewMHz-0q8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Compare Linear and Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFwCy5qB7dCI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5kT3B7oUrsL",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "linreg = LinearRegression()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, shuffle=False, random_state=11)\n",
        "linreg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = linreg.predict(X_test)\n",
        "root_mean_squared_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBNcBWD3U5IZ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i1rvOWR_jQs",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The only change that we have to made is importing Ridge instead of Linear Regression.\n",
        "\n",
        "Ridge Regression has a penalty called alpha. The higher alpha, the stronger the reguluraization. That means that we penalty on overfitting and highly correlating is stronger and that the model tries to correct these negative influences.\n",
        "\n",
        "If we set alpha = 0 Ridge Regression is equivalent to the Linear Regression (no penalty)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkW6Y7GSU71C",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge #import ridge\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ridgereg = Ridge(alpha=0) # set alpha to 0 > equivalent to linear model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, shuffle=False, random_state=11)\n",
        "ridgereg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = ridgereg.predict(X_test)\n",
        "root_mean_squared_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRjIv6-IVDj3",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Compare Regression Coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDf3pXRB_Dt5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Let's define a small helper function that helps us interpreting the regression coefficients!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1emwf09SQ4oS",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def get_coefs(model, X_train):\n",
        "  coef_table = pd.DataFrame(list(X_train.columns)).copy()\n",
        "  coef_table.insert(len(coef_table.columns),\"Coefs\",model.coef_.transpose())\n",
        "  return coef_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nltPIy5RAOca",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Regression Coefficients for the Linear Regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXmq_Tlr86dT",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "get_coefs(linreg, X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmf2-SVyATyV",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Identical Regression Coefficients for the Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHDNYW3N9C_u",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "get_coefs(ridgereg, X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vDkBAQnsjmq",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Let's Penalize our Regression: Increasing alpha to 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s16IG6UCdKG2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "ridgereg = Ridge(alpha=20) # set alpha from 0 to 20 (alpha must be >0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.12, shuffle=False, random_state=11)\n",
        "ridgereg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = ridgereg.predict(X_test)\n",
        "root_mean_squared_error(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G5PGTMr-8az",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Increasing an alpha an putting a stronger penalty on variables the are highly correlating with other variables and that increase overfitting, we get a more accurate model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2QqYKdL-hbb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "get_coefs(ridgereg, X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrYPFu3A_JvI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We regression coefficients have changed quite drastically! Look at grow.temp its influence has been decreased from 21.35 in the linear regression to 8.97 in the Ridge Regression Model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-8iftHcBtVp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Can you find a better alpha for increasing model performance?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Ridge Regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}