{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u9in3e0XVXn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hands On - Predicting Customer Churn - Introduction to Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NA2JhnVX6ZL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTcyOOect_tE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "churn = pd.read_csv(\"https://raw.githubusercontent.com/casbdai/datasets/main/churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94kjRIcJoy53",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check Structure of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3rakrkKpE0m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "churn.______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66scpIgU4yiD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "*   No missing data\n",
    "*   23 Features\n",
    "* Some features are objects (text data). We need to transform them because scikit-learn cannot work with them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHWHGAZIR9p5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "churn.______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SGlLhLneurF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Separate Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vkKVc94wLU0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = ______ # Features\n",
    "y = ______ # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zBHmkB6YNZI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4imhqkuYJBG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGGSu_imfIpc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Recode pandas \"objects\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ppw-RjFPfVX8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\"Objects\" in Pandas are textual variables. Sklearn cannot work with them. We have to recode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JhLfcWvZ9lm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "churn[\"occupation\"].unique() #unique returns the unique values for a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s6IdoX4ekB4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eb1BczLycIPf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_onehot = pd.get_dummies(X, drop_first = False)\n",
    "X_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiaGHntKpSN2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Check out feature \"customer_suspended\". Due to the onehot encoding there is now a \"customer_suspended_Yes\" and a \"customer_suspended_No\" version. Of course, both variables contain the same information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_Z7kWHvgDe8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dummy coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUIEXuxdfz52",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first = ______)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXK1vSvc5K_B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Adding the argument \"drop_first = True\" deletes the redundant features.\n",
    "\n",
    "Some algorithms have problems with dealing with the redundant information (e.g. linear models). Thus, dummy coding is a safer bet without loosing any information (= preferred choice)\n",
    "\n",
    "Bet we now have a bigger number of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhDcbhix5s0d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2) Create Test & Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPhsoSfyr9Ir",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrUugRObSG5G",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "*   **X:** Features to be split into testing and training data\n",
    "*   **y:** Labels to be split into testing and training data\n",
    "*   **test_size:** proportion of the dataset in the test data; usually ~ 30%\n",
    "*   **random_state:** seed for making results reproducible. Instances are randomly distributed among testing and training data. However, every computer splits randomly in a different fashion. Providing a seed, makes results reproducible because with the same seed, all computers split the data in the same fashion.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwa-RwDpVovW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use the .shape method to investigate whether data splitting has been succesfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMB247ALsWtG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.shape #4863 instances and 25 variables in the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "094xl5O0spdL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train.______ #3404 instances and 25 variables in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5dqy60tsyWy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_test.______ #1459 instances and 25 variables in the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3) Import, Initiate, and Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree_educatedguess = DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                              max_depth=30,\n",
    "                              min_samples_leaf=50,\n",
    "                              random_state=12)\n",
    "tree_educatedguess.fit(______, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000)\n",
    "______.______(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5)\n",
    "boost.fit(______,______)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7IDN2qY0Hlq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluating Model Performance the Business Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB8GSZ6Mxp8a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We need to install the scikit-plot library:\n",
    "\n",
    "\n",
    "*  **Google Collab:** The following command needs to be executed every time the notebook is started (installations are deleted on collab after the notbook is closed.\n",
    "* **Jupyter:** It has to be installed only once (as it is installed in the local python environment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEelB-s7U7O3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOtg9GI5y825",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lift Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBCEom4UzNYk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "scikit-plot is already imported and we have already predictions at the customer level (y_pred)\n",
    "\n",
    "We can directly draw the lift curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IMMO-mpVoaR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "y_pred = boost.predict_proba(X_test)\n",
    "skplt.metrics.plot_lift_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKxlvOF_cnzJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = tree_educatedguess.predict_proba(X_test)\n",
    "skplt.metrics.plot_lift_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGRyggV0zqUg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Expected Value of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4O22uCF0g5-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define value of business outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Upfgyizv0box",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "value_true_positive = 186\n",
    "value_false_positive = -30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x47S0fCZ1IHp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define Function for Scoring Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_X-qvTsDax-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_expected_value_model(matrix, value_true_positive, value_false_positive):\n",
    "  \"\"\" works only for confusion matrices in specified form \"\"\"\n",
    "\n",
    "  #calculate prior probability of positive class\n",
    "  p_prior_pos = matrix[1,:].sum() / matrix.sum() \n",
    "  \n",
    "   #calculate conditional probabilities\n",
    "  p_neg_instances = matrix[0,:]/matrix[0,:].sum()\n",
    "  p_pos_instances = matrix[1,:]/matrix[1,:].sum() \n",
    "\n",
    "  # calculate expected values\n",
    "  pos = p_prior_pos * (value_true_positive * p_pos_instances[1] + 0 * p_pos_instances[0])\n",
    "  neg = (1 - p_prior_pos) * (value_false_positive * p_neg_instances[1] + 0 * p_neg_instances[0])\n",
    "  return round(pos + neg, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gflpVA971R0p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get Expected Value for each contacted customer for random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOEqvikBEj-_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = forest.predict(X_test)\n",
    "matrix = confusion_matrix(y_test,y_pred)\n",
    "calculate_expected_value_model(matrix, value_true_positive, value_false_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNyCwH8OIyDx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get Expected Value for each contacted customer for decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = tree_educatedguess.predict(X_test)\n",
    "matrix = confusion_matrix(y_test,y_pred)\n",
    "calculate_expected_value_model(matrix, value_true_positive, value_false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Introduction to Machine Learning - Classification COMPLETED.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
