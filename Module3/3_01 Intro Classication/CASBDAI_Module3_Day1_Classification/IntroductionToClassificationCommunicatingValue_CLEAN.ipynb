{"cells":[{"cell_type":"markdown","source":["# Classification - Communicating Performance to Business "],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"nYBgeqQyyU7U"}},{"cell_type":"markdown","source":["## 1) Import & Prepare Data"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"W0Rx5n_qyU7a"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import pandas as pd\n","churn = pd.read_csv(\"https://raw.githubusercontent.com/casbdai/datasets/main/churn.csv\")"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"QnQI3pZfyU7b"}},{"cell_type":"markdown","source":["### Check Structure of Data"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"tEUAX4N-yU7c"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["churn.info()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"rlb6nEi8yU7d"}},{"cell_type":"markdown","source":["### Separate Features and Labels"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"J7-95zzJyU7d"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["X = churn.drop(\"churn\",axis=1) # Features\n","y = churn[\"churn\"] # Target variable"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"ZQuaZ9-0yU7e"}},{"cell_type":"markdown","source":["### Dummy code pandas \"objects\""],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"UkmYmnXoyU7f"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["X = pd.get_dummies(X, drop_first = True)\n","X.head()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"3uR0x1layU7g"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["X.info()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"C0U6OmqZyU7g"}},{"cell_type":"markdown","source":["## 2) Create Test & Training Data\n"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"n1hFt-3xyU7h"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sklearn.model_selection import train_test_split"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"oIUYx0jXyU7h"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"QNwM0r_byU7h"}},{"cell_type":"markdown","source":["\n","*   **X:** Features to be split into testing and training data\n","*   **y:** Labels to be split into testing and training data\n","*   **test_size:** proportion of the dataset in the test data; usually ~ 30%\n","*   **random_state:** seed for making results reproducible. Instances are randomly distributed among testing and training data. However, every computer splits randomly in a different fashion. Providing a seed, makes results reproducible because with the same seed, all computers split the data in the same fashion.\n","\n","\n"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"AKlc7UBGyU7i"}},{"cell_type":"markdown","source":["## 3) Import, Initiate, and Train Models"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"rk_h8EVpyU7i"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"uB3KhH6VyU7j"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["tree_educatedguess = DecisionTreeClassifier(criterion=\"entropy\",\n","                              max_depth=30,\n","                              min_samples_leaf=50,\n","                              random_state=12)\n","tree_educatedguess.fit(X_train, y_train)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"jbCxERPYyU7j"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["forest = RandomForestClassifier(n_estimators=1000)\n","forest.fit(X_train,y_train)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"jTZsgNuOyU7k"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5)\n","boost.fit(X_train,y_train)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"fyg8uEYUyU7l"}},{"cell_type":"markdown","source":["# Evaluating Model Performance the Business Way"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"dPFY3hhCyU7m"}},{"cell_type":"markdown","source":["## Lift Curve"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"FIRL510jyU7m"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def plot_lift_curve(y_val, y_pred):\n","    \"\"\" calculation and plotting of model lift \"\"\"\n","    \n","    from pandas import DataFrame\n","    from numpy import ceil, arange\n","    import matplotlib.pyplot as plt\n","    \n","    #Define an auxiliar dataframe to plot the curve\n","    aux_lift = DataFrame()\n","    aux_lift['true'] = y_val\n","    aux_lift['predicted'] = y_pred\n","    aux_lift.sort_values('predicted', ascending=False, inplace=True)\n","    \n","    #Create the values that will go into the X axis of our plot\n","    xval = arange(0.01,1.01,0.01) #create sequnence of values from 0.01 to 1.00 in steps of 0.01\n","    lift = [] #create empty list for storing lift values\n","    \n","    #Calculate the total ratio of true events in the data\n","    ratio_true_events_total = aux_lift['true'].sum() / len(aux_lift)\n","    \n","    #Calculate lift for each x value its correspondent y value\n","    for x in xval:\n","        index_xval = int(ceil(x*len(aux_lift))) #get index at specific value of x\n","        dataframe_xval = aux_lift.iloc[:index_xval,:]   #subset dataframe from 0 to index_val\n","        lift_xval = dataframe_xval['true'].sum()/len(dataframe_xval) #calculate lift for subset\n","        lift.append(lift_xval / ratio_true_events_total) #store results\n","    \n","    #Build results dataframe\n","    lift = DataFrame({\"Lift\":lift, \"ProportionSample\":xval})\n","    \n","    #Create plot\n","    fig, ax = plt.subplots(figsize = (13,5), dpi=300)\n","    ax.plot(lift[\"ProportionSample\"],lift[\"Lift\"], color='green', linewidth = 3, label = \"Model\")\n","    ax.plot([0,1],[1,1],color=\"grey\", label=\"Baseline\")\n","    ax.set_xlabel('\\nProportion of sample', fontsize=13)\n","    ax.set_ylabel('Lift\\n', fontsize=13)\n","    ax.set_title('Lift Curve\\n', fontsize=15)\n","    ax.xaxis.set_tick_params(labelsize=11)\n","    ax.yaxis.set_tick_params(labelsize=11)\n","    ax.legend()\n","    plt.show()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"PHFN2RQsyU7n"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"pAPuGhnOyU7n"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"fOH6gUDwyU7o"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"XhjlgE5LyU7o"}},{"cell_type":"markdown","source":["## Expected Value of Models"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"XKMd2UFPyU7o"}},{"cell_type":"markdown","source":["Define value of business outcomes "],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"miTi1OMeyU7o"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["value_true_positive = \n","value_false_positive = "],"metadata":{"pycharm":{"name":"#%%\n"},"id":"zEs95ZzByU7o"}},{"cell_type":"markdown","source":["Define Function for Scoring Model:"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"6aUy7Th7yU7p"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def calculate_expected_value_model(matrix, value_true_positive, value_false_positive):\n","  \"\"\" works only for confusion matrices in specified form \"\"\"\n","\n","  #calculate prior probability of positive class\n","  p_prior_pos = matrix[1,:].sum() / matrix.sum() \n","  \n","   #calculate conditional probabilities\n","  p_neg_instances = matrix[0,:]/matrix[0,:].sum()\n","  p_pos_instances = matrix[1,:]/matrix[1,:].sum() \n","\n","  # calculate expected values\n","  pos = p_prior_pos * (value_true_positive * p_pos_instances[1] + 0 * p_pos_instances[0])\n","  neg = (1 - p_prior_pos) * (value_false_positive * p_neg_instances[1] + 0 * p_neg_instances[0])\n","  return round(pos + neg, 2)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"Fop7IMFLyU7p"}},{"cell_type":"markdown","source":["Get Expected Value for each contacted customer for random forest:"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"5sLkhvwoyU7p"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"tAVBzY_ByU7q"}},{"cell_type":"markdown","source":["Get Expected Value for each contacted customer for decision tree:"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"MTOycl9CyU7q"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"43NwRNddyU7q"}},{"cell_type":"markdown","source":["## Get threshold probability"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"mVTnc2jIyU7q"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def calculate_targeting_threshold(value_true_positive, value_false_positive):\n","    from sympy.solvers import solve\n","    from sympy import Symbol\n","    x = Symbol(\"x\")\n","    p = solve(x*value_true_positive + (1-x)*value_false_positive, x)\n","    return float(p[0])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IYnm-ux3yU7r"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[],"metadata":{"pycharm":{"name":"#%%\n"},"id":"tqwTEaPSyU7r"}}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}