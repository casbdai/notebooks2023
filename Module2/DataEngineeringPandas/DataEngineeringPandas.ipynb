{"cells":[{"cell_type":"markdown","metadata":{"id":"aDwn5eM3zIJW"},"source":["# Hands on - Applied data engineering with Pandas"]},{"cell_type":"markdown","metadata":{"id":"pAKh9GFq0oZc"},"source":["### ...or creating a simple ETL process"]},{"cell_type":"markdown","metadata":{"id":"aOSDvDxozHiv"},"source":["In this hands-on session, we will again work with the data from the ACM case. However, in the last module some data scientists have already invested some time in data engineering and wrangling.\n","\n","Given our newly gained pandas skills, we now want to follow their path...\n"]},{"cell_type":"markdown","metadata":{"id":"Yu2NygGrzjMJ"},"source":["# 1) Importing Files"]},{"cell_type":"markdown","metadata":{"id":"EQ5cONJbzn-B"},"source":["Import the survey data into pandas. However, the survey data is stored in three different sheets in the data file (\"2019\", \"2020\", and \"2021\"). Load them into pandas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGIK3z456lzj","vscode":{"languageId":"python"}},"outputs":[],"source":["import ________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-meGRa_e0VJs","vscode":{"languageId":"python"}},"outputs":[],"source":["survey2019 = pd.read_excel(\"https://github.com/casbdai/notebooks2023/raw/main/Module2/DataEngineeringPandas/Pandas_TV_Survey_Data.xlsx\", sheet_name=\"2019\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAe8SgQ00ZJ8","vscode":{"languageId":"python"}},"outputs":[],"source":["survey2020 = ________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjUBmEsF5z6S","vscode":{"languageId":"python"}},"outputs":[],"source":["survey2021 = ________"]},{"cell_type":"markdown","metadata":{"id":"YPbYaYC054lp"},"source":["Have a look at the three dataframes. They all have the same sructure and identical variable names. Paste theme together into a new dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJrLJQmSPXcX","vscode":{"languageId":"python"}},"outputs":[],"source":["survey2019.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FxqIqMx53Xp","vscode":{"languageId":"python"}},"outputs":[],"source":["survey2019.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBP9KksKARiZ","vscode":{"languageId":"python"}},"outputs":[],"source":["survey2020.________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQjvlRUnAXWI","vscode":{"languageId":"python"}},"outputs":[],"source":["survey2021.________"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4XxF9uG1zImM"},"source":["Combine files row-wise or column-wise\n","\n","*   set **axis=0** to row-wise combination\n","*   set **axis=1** to column-wise combination"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAig3f0S6uAz","vscode":{"languageId":"python"}},"outputs":[],"source":["survey = pd.concat([survey2019, survey2020, survey2021], axis = 0)\n","________"]},{"cell_type":"markdown","metadata":{"id":"RC8m3K3f6X57"},"source":["Now also read in the intentionality results using an appropriate reading function. Watch out for the delimeter!\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNAD1ZhhCNyB","vscode":{"languageId":"python"}},"outputs":[],"source":["intentionality = pd.________(\"https://raw.githubusercontent.com/casbdai/notebooks2023/main/Module2/DataEngineeringPandas/Pandas_TV_Intentionality_Data.csv\", sep=\"________\")\n","________"]},{"cell_type":"markdown","metadata":{"id":"KjzZ81ouEmub"},"source":["We need to fix the variable type of \"date\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1687518350143,"user":{"displayName":"Ivo Blohm","userId":"03588522102684867783"},"user_tz":-120},"id":"WCEoTk1HER_q","outputId":"267d471c-370c-4d34-b900-a026a0a903a3","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7846 entries, 0 to 7845\n","Data columns (total 4 columns):\n"," #   Column          Non-Null Count  Dtype         \n","---  ------          --------------  -----         \n"," 0   date            7846 non-null   datetime64[ns]\n"," 1   IndustryAdType  7846 non-null   object        \n"," 2   ProgramName     7846 non-null   object        \n"," 3   Intentionality  7846 non-null   float64       \n","dtypes: datetime64[ns](1), float64(1), object(2)\n","memory usage: 245.3+ KB\n"]}],"source":["intentionality.date = pd.to_datetime(intentionality.date)\n","intentionality.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5OxSvh7OW5l","vscode":{"languageId":"python"}},"outputs":[],"source":["gtrends = pd.read_excel(\"https://github.com/casbdai/notebooks2023/raw/main/Module2/DataEngineeringPandas/Pandas_TV_GTrends_Data.xlsx\")\n","gtrends.info()"]},{"cell_type":"markdown","metadata":{"id":"Qt7cWGcv6xSL"},"source":["# 2) Merging Files"]},{"cell_type":"markdown","metadata":{"id":"cnqstDis62ks"},"source":["Now after having loaded the data, we want to combine the data into one overarching data set. However, be aware that the data needs to be joined on three variables: Industry Ad Type, Program Name and date / Date Aired"]},{"cell_type":"markdown","metadata":{"id":"P7oYPqQt7AuJ"},"source":["Perform an inner join of the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxVl3_JZ7LP6","vscode":{"languageId":"python"}},"outputs":[],"source":["inner =  pd.merge(survey, intentionality,\n","                  how=\"inner\",\n","                  left_on=[\"IndustryAdType\", \"ProgramName\", \"DateAired\"],\n","                  right_on=[\"IndustryAdType\", \"ProgramName\", \"date\"])\n","\n","inner.info()"]},{"cell_type":"markdown","metadata":{"id":"LX8LGM9X76a2"},"source":["Perform an left join of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DztglyDr8JXa","vscode":{"languageId":"python"}},"outputs":[],"source":["left =  pd.merge(________, ________,\n","                  how=________,\n","                  left_on=[________, ________, ________],\n","                  right_on=[________, ________,________])\n","\n","left.info()"]},{"cell_type":"markdown","metadata":{"id":"Kk1FNbf68Mz7"},"source":["How many NaNs are introduced in the variable intentionality? (you can use .info() )"]},{"cell_type":"markdown","metadata":{"id":"SOJyo27A8SmD"},"source":["Number of NaN: __"]},{"cell_type":"markdown","metadata":{"id":"Jbiv3Y8D8h9y"},"source":["Which joining method would you use for combining the two dataframe? Why?\n","\n","Your answer: __________________________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LaHV70-SPOzG","vscode":{"languageId":"python"}},"outputs":[],"source":["left =  pd.________(________, ________,\n","                  how=________,\n","                  left_on=[________, ________],\n","                  right_on=[________, ________])\n","\n","left.info()"]},{"cell_type":"markdown","metadata":{"id":"epHuZCfF8cty"},"source":["# 3) Dealing with NA"]},{"cell_type":"markdown","metadata":{"id":"7efJ9igX8sHy"},"source":["In order to practice our \"dealing with missing data skills\", we have to decided to go with an outer join."]},{"cell_type":"markdown","metadata":{"id":"jfddwdGE9QmB"},"source":["Create a new dataframe in which you have removed all missing values:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjjA73ZP9Jdr","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata = left.dropna()\n","acmdata.info()"]},{"cell_type":"markdown","metadata":{"id":"DWWRpp5B9YxQ"},"source":["Create a new dataframe in which you insert 0 into the missing data fields of appropriate variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1qEZLMQ9kWv","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata_0 = left.fillna(value=0)\n","acmdata_0.info()"]},{"cell_type":"markdown","metadata":{"id":"hJ3ddKFdHBLJ"},"source":["# 4) Tranforming Variables"]},{"cell_type":"markdown","metadata":{"id":"UyvN_6QaHP9J"},"source":["In the following exercises, we use the acmdata dataframe!"]},{"cell_type":"markdown","metadata":{"id":"JDFwR5yoHHm4"},"source":["Rename the variable \"Spend\" into \"Spend_in_000\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hv1chLAAHNeA","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata = acmdata.rename(columns={\"Spend\": \"Spend_in_000\"})\n","acmdata.info()"]},{"cell_type":"markdown","metadata":{"id":"7qvj-4Y3J5yh"},"source":["Delete the Variable \"date\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9prekiSVJ46p","vscode":{"languageId":"python"}},"outputs":[],"source":["del(acmdata[\"date_y\"])\n","acmdata.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsiDqr621l7m","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata = acmdata.drop(\"date_x\", axis = 1)\n","acmdata.info()"]},{"cell_type":"markdown","metadata":{"id":"SrmVSsHOKSlw"},"source":["Aggregate the acmdata data frame by \"IndustryAdType\" using .mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1MpspzkKYfb","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata.groupby(\"IndustryAdType\").mean()"]},{"cell_type":"markdown","metadata":{"id":"HSe7JbFJKwUh"},"source":["Aggregate the acm dataframe by \"Industry Ad Type\" and \"Program Name\" using .sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pFN5euA8LBfD","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata.groupby([________, ________]).sum()"]},{"cell_type":"markdown","metadata":{"id":"hVHJXQtZLAzn"},"source":["Again, aggregate the acmdata dataframe by \"Industry Ad Type\" and \"Program Name\" using .sum(). However, you are only interested in the \"Spend\" and \"Impressions\" data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pG9CtTzLimQ","vscode":{"languageId":"python"}},"outputs":[],"source":["________"]},{"cell_type":"markdown","metadata":{"id":"0DA1K2XAMN0D"},"source":["### Meaningful plots: Combining aggregations and .plot()"]},{"cell_type":"markdown","metadata":{"id":"5WHyxR3zMVt_"},"source":["For creating more meaningful and Tableau-like plots in python, you have to combine aggregations with the .plot() method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTT23iL8MNCW","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata.groupby([\"DateAired\"])[\"Spend_in_000\"].sum().plot()"]},{"cell_type":"markdown","metadata":{"id":"pI701HcKM9Dg"},"source":["a barplot of Spend by Program Name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_29EZj3NAHx","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata.groupby([\"ProgramName\"])[\"Spend_in_000\"].sum().plot(kind=\"bar\")"]},{"cell_type":"markdown","metadata":{"id":"TktHTgunNhiN"},"source":["# Writing Data File"]},{"cell_type":"markdown","metadata":{"id":"n-5tzqfRNj0-"},"source":["Now, write the merged and tidied data file as excel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JA3SSRGJQA8E","vscode":{"languageId":"python"}},"outputs":[],"source":["acmdata.to_excel(\"acmdata.xlsx\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687518361507,"user":{"displayName":"Ivo Blohm","userId":"03588522102684867783"},"user_tz":-120},"id":"MGNU6umByNXK","outputId":"a2ba65c6-0725-4c08-ec89-50dd1f270bbf","vscode":{"languageId":"python"}},"outputs":[{"data":{"application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":"download(\"download_e18bb3e6-2e0b-4008-941f-455e9885522c\", \"acmdata.xlsx\", 629533)","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["from google.colab import files\n","files.download('acmdata.xlsx')"]},{"cell_type":"markdown","metadata":{"id":"gib1oLjBINwm"},"source":["Or write the data into an SQL database"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1439,"status":"ok","timestamp":1687518362941,"user":{"displayName":"Ivo Blohm","userId":"03588522102684867783"},"user_tz":-120},"id":"Y945WCTWITTX","outputId":"b360f627-02dc-4021-9bbf-53e59bd90b02","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["['clean_acm_data']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import sqlalchemy as db\n","\n","engine = db.create_engine(\"sqlite:///cleaned_database\")\n","engine.connect()\n","\n","acmdata.to_sql('clean_acm_data', con=engine, if_exists=\"replace\", index=False)\n","\n","inspector = db.inspect(engine)\n","inspector.get_table_names()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1h-Lnr6hfUB-SNsDhZ0op6cznod6OcnT1","timestamp":1578316099624}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
